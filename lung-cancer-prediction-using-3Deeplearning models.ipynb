{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7362503,"sourceType":"datasetVersion","datasetId":4276841},{"sourceId":826,"sourceType":"modelInstanceVersion","modelInstanceId":691}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EfficientNet B5\n## Let's Begin....","metadata":{"id":"DGOlpli75Z_c"}},{"cell_type":"code","source":"# Import Neccessary Lib...\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n\nimport os\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l1, l2","metadata":{"id":"OylMWw9Sh3b3","execution":{"iopub.status.busy":"2024-01-08T13:14:17.111186Z","iopub.execute_input":"2024-01-08T13:14:17.111574Z","iopub.status.idle":"2024-01-08T13:14:30.713922Z","shell.execute_reply.started":"2024-01-08T13:14:17.111544Z","shell.execute_reply":"2024-01-08T13:14:30.712696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory paths\ntrain_dir = '/kaggle/input/lungcancer4types-imagedataset/Data/test'\ntest_dir = '/kaggle/input/lungcancer4types-imagedataset/Data/train'\nvalid_dir = '/kaggle/input/lungcancer4types-imagedataset/Data/valid'","metadata":{"id":"4DHOnXmTh8a_","execution":{"iopub.status.busy":"2024-01-08T13:14:41.670243Z","iopub.execute_input":"2024-01-08T13:14:41.670647Z","iopub.status.idle":"2024-01-08T13:14:41.676293Z","shell.execute_reply.started":"2024-01-08T13:14:41.670617Z","shell.execute_reply":"2024-01-08T13:14:41.675085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Function to create a DataFrame from image files in a folder\ndef create_dataframe(folder_path):\n    # Initialize an empty dictionary to store image paths and labels\n    data = {'Image_Path': [], 'Label': []}\n\n    # List all subdirectories (labels) in the given folder\n    labels = os.listdir(folder_path)\n\n    # Loop through each label\n    for label in labels:\n        # Construct the full path to the label folder\n        label_path = os.path.join(folder_path, label)\n\n        # Check if the path is a directory\n        if os.path.isdir(label_path):\n            # List all image files in the label folder\n            images = os.listdir(label_path)\n\n            # Loop through each image\n            for image in images:\n                # Construct the full path to the image\n                image_path = os.path.join(label_path, image)\n\n                # Append image path and label to the dictionary\n                data['Image_Path'].append(image_path)\n                data['Label'].append(label)\n\n    # Create a DataFrame from the dictionary\n    df = pd.DataFrame(data)\n    return df\n\n# Provide the path to your 'data' folder\ndata_folder = '/kaggle/input/lungcancer4types-imagedataset/Data'\n\n# Create DataFrames for train, test, and valid using the create_dataframe function\ntrain_df = create_dataframe(os.path.join(data_folder, 'train'))\ntest_df = create_dataframe(os.path.join(data_folder, 'test'))\nvalid_df = create_dataframe(os.path.join(data_folder, 'valid'))\n\n# Print the created DataFrames for inspection\nprint(\"Train DataFrame:\")\nprint(train_df.head())","metadata":{"outputId":"67d41380-a800-446f-e017-98e22cb99872","id":"U-4wnr0O8dvF","execution":{"iopub.status.busy":"2024-01-08T13:15:08.356369Z","iopub.execute_input":"2024-01-08T13:15:08.356746Z","iopub.status.idle":"2024-01-08T13:15:08.89236Z","shell.execute_reply.started":"2024-01-08T13:15:08.356718Z","shell.execute_reply":"2024-01-08T13:15:08.891186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\nTest DataFrame:\")\nprint(test_df.head())","metadata":{"id":"c6iuI9JXiLQd","outputId":"e360f402-86ec-4aba-d390-be7e5ded6110","execution":{"iopub.status.busy":"2024-01-08T13:15:14.27877Z","iopub.execute_input":"2024-01-08T13:15:14.279352Z","iopub.status.idle":"2024-01-08T13:15:14.285261Z","shell.execute_reply.started":"2024-01-08T13:15:14.27932Z","shell.execute_reply":"2024-01-08T13:15:14.284532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\nValid DataFrame:\")\nprint(valid_df.head())","metadata":{"id":"0TX-BeALiOEZ","outputId":"68839461-8585-426f-c4e7-dce922db48bb","execution":{"iopub.status.busy":"2024-01-08T13:15:18.195445Z","iopub.execute_input":"2024-01-08T13:15:18.196032Z","iopub.status.idle":"2024-01-08T13:15:18.202872Z","shell.execute_reply.started":"2024-01-08T13:15:18.196Z","shell.execute_reply":"2024-01-08T13:15:18.20189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of unique classes (labels) in the 'Label' column of the training DataFrame\nnum_classes = len(train_df['Label'].unique())\n\n# Print the number of classes in the dataset\nprint(f\"We have {num_classes} classes\")\n\n# Print the total number of images in the training DataFrame (total rows)\nprint(f\"We have {train_df.shape[0]} images\")","metadata":{"id":"dKwwZ0aXiS8Y","outputId":"17a1d131-9684-4e97-eb98-d836de207eb6","execution":{"iopub.status.busy":"2024-01-08T13:15:21.258542Z","iopub.execute_input":"2024-01-08T13:15:21.25893Z","iopub.status.idle":"2024-01-08T13:15:21.271224Z","shell.execute_reply.started":"2024-01-08T13:15:21.258898Z","shell.execute_reply":"2024-01-08T13:15:21.270309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of unique classes (labels) in the 'Label' column of the test DataFrame\nnum_classes = len(test_df['Label'].unique())\n\n# Print the number of classes in the dataset\nprint(f\"We have {num_classes} classes\")\n\n# Print the total number of images in the test DataFrame (total rows)\nprint(f\"We have {test_df.shape[0]} images\")","metadata":{"id":"C8DIiGIwijaq","outputId":"6e7a4904-4c58-4dcc-84d6-4bd02b00df6a","execution":{"iopub.status.busy":"2024-01-08T13:15:23.737089Z","iopub.execute_input":"2024-01-08T13:15:23.737482Z","iopub.status.idle":"2024-01-08T13:15:23.744057Z","shell.execute_reply.started":"2024-01-08T13:15:23.737452Z","shell.execute_reply":"2024-01-08T13:15:23.742864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of unique classes (labels) in the 'Label' column of the valid DataFrame\nnum_classes = len(valid_df['Label'].unique())\n\n# Print the number of classes in the dataset\nprint(f\"We have {num_classes} classes\")\n\n# Print the total number of images in the valid DataFrame (total rows)\nprint(f\"We have {valid_df.shape[0]} images\")","metadata":{"id":"OhbkmbZqinKY","outputId":"4ca3a84a-3ef7-41cd-dca5-024b6afe66fd","execution":{"iopub.status.busy":"2024-01-08T13:15:27.353584Z","iopub.execute_input":"2024-01-08T13:15:27.353957Z","iopub.status.idle":"2024-01-08T13:15:27.361448Z","shell.execute_reply.started":"2024-01-08T13:15:27.353928Z","shell.execute_reply":"2024-01-08T13:15:27.360619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the size of the input images\nimg_size = (224, 224)\n\n# Specify the number of color channels in the images (3 for RGB)\nchannels = 3\n\n# Specify the color representation ('rgb' for red, green, blue)\ncolor = 'rgb'\n\n# Define the shape of the input images based on size, channels, and color representation\nimg_shape = (img_size[0], img_size[1], channels)\n\n# Specify the batch size for training\nbatch_size = 32\n\n# Get the length of the test DataFrame\nts_length = len(test_df)\n\n# Determine an optimal test batch size that evenly divides the length of the test DataFrame\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length % n == 0 and ts_length / n <= 80]))\n\n# Calculate the number of steps needed to cover the entire test dataset\ntest_steps = ts_length // test_batch_size\n\n# Define a function 'scalar' that takes an image as input (placeholder, no implementation provided)\ndef scalar(img):\n    return img\n","metadata":{"id":"7H00Xv0riwXL","execution":{"iopub.status.busy":"2024-01-08T13:15:32.900741Z","iopub.execute_input":"2024-01-08T13:15:32.901164Z","iopub.status.idle":"2024-01-08T13:15:32.908425Z","shell.execute_reply.started":"2024-01-08T13:15:32.901131Z","shell.execute_reply":"2024-01-08T13:15:32.907346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_gen = ImageDataGenerator(preprocessing_function= scalar,\n                            horizontal_flip= True)\n\n# Create an ImageDataGenerator for training with specified preprocessing and augmentation settings\ntr_gen = ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n\n# Create an ImageDataGenerator for testing with specified preprocessing settings\nts_gen = ImageDataGenerator(preprocessing_function=scalar)\n\n# Generate a flow from DataFrame for training data\ntrain_gen = tr_gen.flow_from_dataframe(\n    train_df,\n    x_col='Image_Path',\n    y_col='Label',\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode=color,\n    shuffle=True,\n    batch_size=batch_size\n)\n\n# Generate a flow from DataFrame for validation data\nvalid_gen = ts_gen.flow_from_dataframe(\n    valid_df,\n    x_col='Image_Path',\n    y_col='Label',\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode=color,\n    shuffle=True,\n    batch_size=batch_size\n)\n\n# Generate a flow from DataFrame for test data\ntest_gen = ts_gen.flow_from_dataframe(\n    test_df,\n    x_col='Image_Path',\n    y_col='Label',\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode=color,\n    shuffle=False,\n    batch_size=test_batch_size\n)\n","metadata":{"id":"QqSOiLrxjjOD","outputId":"e562f193-cc5c-439f-c7b9-18bad8e76fe2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the EfficientNetB5 pre-trained model as a base model (without the fully connected layers)\nbase_model = tf.keras.applications.efficientnet.EfficientNetB5(\n    include_top=False,     # Exclude the fully connected layers\n    weights=\"imagenet\",    # Load pre-trained ImageNet weights\n    input_shape=img_shape,  # Specify the input shape for the model\n    pooling='max'           # Use global max pooling as the final pooling layer\n)\n\n# Constructing the complete model using Sequential API\nmodel = Sequential([\n    base_model,  # EfficientNetB5 as the base model\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),  # Batch normalization layer\n    Dense(256,\n          kernel_regularizer=regularizers.l2(l=0.016),\n          activity_regularizer=regularizers.l1(0.006),\n          bias_regularizer=regularizers.l1(0.006),\n          activation='relu'),  # Dense layer with regularization and ReLU activation\n    Dropout(rate=0.45, seed=123),  # Dropout layer for regularization\n    Dense(4, activation='softmax')  # Output layer with softmax activation for multi-class classification\n])\n\n# Compile the model with specified optimizer, loss function, and evaluation metric\nmodel.compile(\n    optimizer=Adamax(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Display a summary of the model architecture\nmodel.summary()\n","metadata":{"id":"h2iZBYVFkm0n","outputId":"76e92170-c977-4a26-d134-b261838ef813"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve the configuration of the optimizer used in the EfficientNetB5 base model\nmodel.optimizer.get_config()","metadata":{"id":"FhylF03qk8dp","outputId":"b9b8515d-048c-4a1f-829a-78906413760b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define early stopping to halt training if the validation loss doesn't improve for 'patience' consecutive epochs\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=5,\n                           verbose=1)\n# Define model checkpoint to save the best weights during training based on validation loss\ncheckpoint = ModelCheckpoint('model_weights_efficient_B5_2.h5',\n                             monitor='val_loss',\n                             save_best_only=True,\n                             save_weights_only=True,\n                             mode='min',\n                             verbose=1)\n\n# Train the EfficientNetB5 base model on the training data with validation using the generator\n# - x: Training generator\n# - steps_per_epoch: Number of batches to process in each epoch\n# - epochs: Number of training epochs\n# - callbacks: List of callbacks to apply during training (early stopping and model checkpoint)\n# - validation_data: Validation generator for evaluating the model's performance on a separate dataset\n\nhistory = model.fit(x= train_gen,\n                    steps_per_epoch = 20,\n                    epochs= 100,\n                    callbacks=[early_stop, checkpoint],\n                    validation_data = valid_gen)","metadata":{"id":"Ymbza2MYlB2j","outputId":"d8eea6ac-dc3e-4e0c-8525-cdfa875f115f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the total number of samples in the test dataset\nts_length = len(test_df)\n# Determine the optimal test batch size within a reasonable range (1 to 80)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n# Calculate the number of steps to cover the entire test dataset using the determined test batch size\ntest_steps = ts_length // test_batch_size\n\n# Evaluate the EfficientNetB5base model on the training dataset and print the results\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n# Evaluate the EfficientNetB5 base model on the validation dataset and print the results\nvalid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n# Evaluate the EfficientNetB5 base model on the test dataset and print the results\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\n# Print the evaluation results for the training dataset\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\n\n# Print the evaluation results for the validation dataset\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('-' * 20)\n\n# Print the evaluation results for the test dataset\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"id":"mf1mrDrLpGXF","outputId":"85ada66f-d5a3-4cd5-b1ad-b6ab756c89bf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet B5\n## (The Above model is EfficientNetB5 which shows best accuracy compare to other models)\n## Train Accuracy: 100%\n## Validation Accuracy: 90.2%\n## Test Accuracy: 91.11%","metadata":{"id":"3aYDXYnm71Wd"}},{"cell_type":"markdown","source":"# VGG19\n## Train Accuracy: 100%\n## Validation Accuracy: 80.56%\n## Test Accuracy: 79.05%","metadata":{"id":"av1hgCOj-VLh"}},{"cell_type":"markdown","source":"# VGG16\n## Train Accuracy: 100%\n## Validation Accuracy:  79.16%\n## Test Accuracy:  76.19%","metadata":{"id":"shJGEpmM-iSU"}}]}